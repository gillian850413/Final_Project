{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawler of Top US Youtube Channels\n",
    "\n",
    "Course: IS590PR Final Project <br>\n",
    "Web Crawling Date: 04/15/2019 <br>\n",
    "Source: https://socialblade.com/youtube/top/country/us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 250 YOUTUBERS IN UNITED STATES SORTED BY SUBSCRIBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_channels(url): \n",
    "    res = requests.get(url) #get the website, return request.Response object\n",
    "    # print(res.status_code) #statu_code: return 200(found web), 404(not found)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    # get rank\n",
    "    rank = list(range(1, 251))\n",
    "    \n",
    "    grade_div = soup.find_all('div', attrs={'style': 'float: left; width: 70px; font-size: 1.1em;'}) # get grade\n",
    "    name_div = soup.find_all('div', attrs={'style': 'float: left; width: 350px; line-height: 25px;'}) # get name\n",
    "    uploads_div = soup.find_all('div', attrs={'style': 'float: left; width: 80px;'}) # get uploads\n",
    "    subs_views_div = soup.find_all('div', attrs={'style': 'float: left; width: 150px;'}) # get subs and views \n",
    "    \n",
    "    uploads_div = uploads_div[1:]\n",
    "    subs_div = subs_views_div[2::2]\n",
    "    views_div = subs_views_div[3::2]\n",
    "    \n",
    "    grade = [] \n",
    "    name = []\n",
    "    url = []\n",
    "    uploads = []\n",
    "    subs = []\n",
    "    views = []\n",
    "    for i in range(250):\n",
    "        # grade list\n",
    "        grade_text = re.split('\\n| ',grade_div[i].text)\n",
    "        grade.append(grade_text[1])\n",
    "\n",
    "        \n",
    "        # name list\n",
    "        name_text = re.split('\\n| \\s',name_div[i].text)\n",
    "        name_text = ''.join(name_text)\n",
    "        name.append(name_text)\n",
    "        \n",
    "        # url list\n",
    "        url_channel = name_div[i].find_all('a')[0].get('href')\n",
    "        url_main = 'https://socialblade.com'\n",
    "        url.append(url_main+url_channel)\n",
    "        \n",
    "        # get uploads text\n",
    "        uploads_text = re.split('\\n| ',uploads_div[i].text)\n",
    "        uploads.append(int(re.sub(\"[^\\d\\.]\", \"\", uploads_text[0]))) # upload list\n",
    "        \n",
    "        # get subs and views text\n",
    "        subs_text = re.split('\\n| ',subs_div[i].text)\n",
    "        views_text = re.split('\\n| ',views_div[i].text)\n",
    "        \n",
    "        # ignore the \n",
    "        try:\n",
    "            subs.append(int(re.sub(\"[^\\d\\.]\", \"\", subs_text[1]))) # subscribers list\n",
    "            views.append(int(re.sub(\"[^\\d\\.]\", \"\", views_text[1]))) # views list\n",
    "        except ValueError:\n",
    "            subs.append(subs_text[1]) # subscribers list\n",
    "            views.append(views_text[1]) # views list            \n",
    "\n",
    "    return rank, grade, name, uploads, subs, views, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_info(url_list):\n",
    "    # daily average subscribers and views are calculated based on the subs and views in the past 30 days\n",
    "    daysubs_list = []\n",
    "    dayviews_list = []\n",
    "    min_day_earn_list = []\n",
    "    max_day_earn_list = []\n",
    "    min_mon_earn_list = []\n",
    "    max_mon_earn_list = []\n",
    "    min_year_earn_list = []\n",
    "    max_year_earn_list = []\n",
    "    category_list = []\n",
    "    created_date_list = []\n",
    "    sub_world_rank_list = []\n",
    "    view_world_rank_list = []\n",
    "    \n",
    "    \n",
    "    for url in url_list:\n",
    "        # print(url)\n",
    "        res = requests.get(url) \n",
    "        # print(res.status_code) \n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        \n",
    "        # get channel type \n",
    "        category_a = soup.find_all('a', attrs={'id': 'youtube-user-page-channeltype'})\n",
    "        category_list.append(category_a[0].text)\n",
    "        \n",
    "        # get created date\n",
    "        created_date_div = soup.find_all('div', attrs={'class': 'YouTubeUserTopInfo'})\n",
    "        created_date = created_date_div[-1].find_all('span', attrs={'style': 'font-weight: bold;'})[0].text\n",
    "        created_date_list.append(created_date)\n",
    "        \n",
    "        # get world subscriber rank\n",
    "        sub_p = soup.find_all('p', attrs={'id': 'afd-header-subscriber-rank'})\n",
    "        sub_world_rank = re.sub(\"[^\\d]\", \"\", sub_p[0].text)\n",
    "        sub_world_rank_list.append(sub_world_rank)\n",
    "        \n",
    "        # get world view rank\n",
    "        view_p = soup.find_all('p', attrs={'id': 'afd-header-videoview-rank'})\n",
    "        view_world_rank = re.sub(\"[^\\d]\", \"\", view_p[0].text)\n",
    "        view_world_rank_list.append(view_world_rank)\n",
    "        \n",
    "        # get daily average subscribers / views / estimated earnings\n",
    "        daysubs_earnings_div = soup.find_all('div', attrs={'style': 'width: 205px; height: 40px; line-height: 40px; float: left;'})\n",
    "        dayviews_div = soup.find_all('div', attrs={'id': 'averagedailyviews'})\n",
    "        # get monthly / yearly estimated earnings\n",
    "        month_year_earning = soup.find_all('p', attrs={'style': 'font-size: 1.4em; color:#41a200; font-weight: 600; padding-top: 20px;'})\n",
    "        \n",
    "        \n",
    "        # get daily average subscribers\n",
    "        daysubs = re.split('\\n| ',daysubs_earnings_div[0].text)[1]\n",
    "        daysubs = re.sub(\"[^-\\d\\.]\", \"\", daysubs)\n",
    "        daysubs_list.append(daysubs)\n",
    "        \n",
    "        # get daily average views\n",
    "        dayviews = re.split('\\n| ',dayviews_div[0].text)[1]\n",
    "        dayviews = re.sub(\"[^-\\d\\.]\", \"\", dayviews)\n",
    "        dayviews_list.append(dayviews)\n",
    "        \n",
    "        # get min estimated earnings \n",
    "        min_day_earn = re.split('\\n| ',daysubs_earnings_div[1].text)[1]\n",
    "        min_mon_earn = re.split('\\n| ',month_year_earning[0].text)[1]\n",
    "        min_year_earn = re.split('\\n| ',month_year_earning[1].text)[1]\n",
    "        \n",
    "        # change string to float (ex: $10k -> 10000.0)\n",
    "        try:\n",
    "            if 'K' in min_day_earn:\n",
    "                min_day_earn = float(re.sub(\"[^-\\d\\.]\", \"\", min_day_earn)) * 1000\n",
    "            elif 'M' in min_day_earn:\n",
    "                min_day_earn = float(re.sub(\"[^-\\d\\.]\", \"\", min_day_earn)) * 1000000\n",
    "            else:\n",
    "                min_day_earn = float(re.sub(\"[^-\\d\\.]\", \"\", min_day_earn))\n",
    "\n",
    "            if 'K' in min_mon_earn:\n",
    "                min_mon_earn = float(re.sub(\"[^-\\d\\.]\", \"\", min_mon_earn)) * 1000\n",
    "            elif 'M' in min_mon_earn:\n",
    "                min_mon_earn = float(re.sub(\"[^-\\d\\.]\", \"\", min_mon_earn)) * 1000000\n",
    "            else:\n",
    "                min_mon_earn = float(re.sub(\"[^-\\d\\.]\", \"\", min_mon_earn))\n",
    "\n",
    "            if 'K' in min_year_earn:\n",
    "                min_year_earn = float(re.sub(\"[^-\\d\\.]\", \"\", min_year_earn)) * 1000\n",
    "            elif 'M' in min_year_earn:\n",
    "                min_year_earn = float(re.sub(\"[^-\\d\\.]\", \"\", min_year_earn)) * 1000000\n",
    "            else:\n",
    "                min_year_earn = float(re.sub(\"[^-\\d\\.]\", \"\", min_year_earn))\n",
    "                \n",
    "        except ValueError:\n",
    "            pass\n",
    "        min_day_earn_list.append(min_day_earn)\n",
    "        min_mon_earn_list.append(min_mon_earn)\n",
    "        min_year_earn_list.append(min_year_earn)\n",
    "        \n",
    "        # get  max estimated earnings \n",
    "        max_day_earn = re.split('\\n| ',daysubs_earnings_div[1].text)[3]\n",
    "        max_mon_earn = re.split('\\n| ',month_year_earning[0].text)[3]\n",
    "        max_year_earn = re.split('\\n| ',month_year_earning[1].text)[3]\n",
    "        # print(max_year_earn)\n",
    "        try:\n",
    "            if 'K' in max_day_earn:\n",
    "                max_day_earn = float(re.sub(\"[^-\\d\\.]\", \"\", max_day_earn)) * 1000\n",
    "            elif 'M' in max_day_earn:\n",
    "                max_day_earn = float(re.sub(\"[^-\\d\\.]\", \"\", max_day_earn)) * 1000000\n",
    "            else:\n",
    "                max_day_earn = float(re.sub(\"[^-\\d\\.]\", \"\", max_day_earn))\n",
    "                \n",
    "            if 'K' in max_mon_earn:\n",
    "                max_mon_earn = float(re.sub(\"[^-\\d\\.]\", \"\", max_mon_earn)) * 1000\n",
    "            elif 'M' in max_mon_earn:\n",
    "                max_mon_earn = float(re.sub(\"[^-\\d\\.]\", \"\", max_mon_earn)) * 1000000\n",
    "            else:\n",
    "                max_mon_earn = float(re.sub(\"[^-\\d\\.]\", \"\", max_mon_earn))\n",
    "\n",
    "            if 'K' in max_year_earn:\n",
    "                max_year_earn = float(re.sub(\"[^-\\d\\.]\", \"\", max_year_earn)) * 1000\n",
    "            elif 'M' in max_year_earn:\n",
    "                max_year_earn = float(re.sub(\"[^-\\d\\.]\", \"\", max_year_earn)) * 1000000\n",
    "            else:\n",
    "                max_year_earn = float(re.sub(\"[^-\\d\\.]\", \"\", max_year_earn))\n",
    "            \n",
    "        except ValueError:\n",
    "            pass\n",
    "        max_day_earn_list.append(max_day_earn)\n",
    "        max_mon_earn_list.append(max_mon_earn)\n",
    "        max_year_earn_list.append(max_year_earn)\n",
    "        # print(max_year_earn_list)\n",
    "\n",
    "    \n",
    "    channel_info = {'Category': category_list, 'Created Date': created_date_list, 'Daily Average Subs': daysubs_list,\n",
    "                   'Daily Average Views': dayviews_list, 'Min Daily Earning': min_day_earn_list, \n",
    "                   'Max Daily Earning': max_day_earn_list, 'Min Monthly Earning': min_mon_earn_list, \n",
    "                   'Max Monthly Earning': max_mon_earn_list, 'Min Yearly Earning': min_year_earn_list,\n",
    "                   'Max Yearly Earning': max_year_earn_list, 'World Subscriber Rank': sub_world_rank_list,\n",
    "                   'World Video View Rank': view_world_rank_list}\n",
    "\n",
    "    \n",
    "    return channel_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_by_subs = 'https://socialblade.com/youtube/top/country/us/mostsubscribed'\n",
    "# url_by_grade = 'https://socialblade.com/youtube/top/country/us'\n",
    "# url_by_views = 'https://socialblade.com/youtube/top/country/us/mostviewed'\n",
    "rank, grade, name, uploads, subs, views, url = get_top_channels(url_by_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_rank = {'US Rank': rank,'Grade': grade,'Name': name, \n",
    "                'Uploads': uploads, 'Subscribers': subs, 'Views': views}\n",
    "url_dict = {'URL': url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_indo = get_channel_info(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = dict(channel_rank, **channel_indo, **url_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US Rank</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Name</th>\n",
       "      <th>Uploads</th>\n",
       "      <th>Subscribers</th>\n",
       "      <th>Views</th>\n",
       "      <th>Category</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Daily Average Subs</th>\n",
       "      <th>Daily Average Views</th>\n",
       "      <th>Min Daily Earning</th>\n",
       "      <th>Max Daily Earning</th>\n",
       "      <th>Min Monthly Earning</th>\n",
       "      <th>Max Monthly Earning</th>\n",
       "      <th>Min Yearly Earning</th>\n",
       "      <th>Max Yearly Earning</th>\n",
       "      <th>World Subscriber Rank</th>\n",
       "      <th>World Video View Rank</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A+</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>3806</td>\n",
       "      <td>94275479</td>\n",
       "      <td>21161543119</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Apr 29th, 2010</td>\n",
       "      <td>146229</td>\n",
       "      <td>13416000</td>\n",
       "      <td>3400</td>\n",
       "      <td>53700</td>\n",
       "      <td>100600</td>\n",
       "      <td>1.6e+06</td>\n",
       "      <td>1.2e+06</td>\n",
       "      <td>1.93e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>https://socialblade.com/youtube/user/pewdiepie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A+</td>\n",
       "      <td>5-Minute Crafts</td>\n",
       "      <td>2973</td>\n",
       "      <td>53832999</td>\n",
       "      <td>13291598454</td>\n",
       "      <td>Howto</td>\n",
       "      <td>Nov 15th, 2016</td>\n",
       "      <td>64674</td>\n",
       "      <td>15396600</td>\n",
       "      <td>3800</td>\n",
       "      <td>61600</td>\n",
       "      <td>115500</td>\n",
       "      <td>1.8e+06</td>\n",
       "      <td>1.4e+06</td>\n",
       "      <td>2.22e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>https://socialblade.com/youtube/user/295-dw_td...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A++</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>416</td>\n",
       "      <td>44131654</td>\n",
       "      <td>25541274029</td>\n",
       "      <td>Education</td>\n",
       "      <td>Sep 1st, 2006</td>\n",
       "      <td>125711</td>\n",
       "      <td>88514800</td>\n",
       "      <td>22100</td>\n",
       "      <td>354100</td>\n",
       "      <td>663900</td>\n",
       "      <td>1.06e+07</td>\n",
       "      <td>8e+06</td>\n",
       "      <td>1.275e+08</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>https://socialblade.com/youtube/user/checkgate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A+</td>\n",
       "      <td>WWE</td>\n",
       "      <td>40805</td>\n",
       "      <td>42100827</td>\n",
       "      <td>31435620458</td>\n",
       "      <td>Sports</td>\n",
       "      <td>May 11th, 2007</td>\n",
       "      <td>45303</td>\n",
       "      <td>24296400</td>\n",
       "      <td>6100</td>\n",
       "      <td>97200</td>\n",
       "      <td>182200</td>\n",
       "      <td>2.9e+06</td>\n",
       "      <td>2.2e+06</td>\n",
       "      <td>3.5e+07</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>https://socialblade.com/youtube/user/wwefannation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>Dude Perfect</td>\n",
       "      <td>202</td>\n",
       "      <td>41275631</td>\n",
       "      <td>7684220326</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Mar 17th, 2009</td>\n",
       "      <td>37131</td>\n",
       "      <td>7820910</td>\n",
       "      <td>2000</td>\n",
       "      <td>31300</td>\n",
       "      <td>58700</td>\n",
       "      <td>938500</td>\n",
       "      <td>703900</td>\n",
       "      <td>1.13e+07</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "      <td>https://socialblade.com/youtube/user/corycotton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   US Rank Grade                        Name  Uploads  Subscribers  \\\n",
       "0        1    A+                   PewDiePie     3806     94275479   \n",
       "1        2    A+             5-Minute Crafts     2973     53832999   \n",
       "2        3   A++  Cocomelon - Nursery Rhymes      416     44131654   \n",
       "3        4    A+                         WWE    40805     42100827   \n",
       "4        5     A                Dude Perfect      202     41275631   \n",
       "\n",
       "         Views       Category    Created Date Daily Average Subs  \\\n",
       "0  21161543119  Entertainment  Apr 29th, 2010             146229   \n",
       "1  13291598454          Howto  Nov 15th, 2016              64674   \n",
       "2  25541274029      Education   Sep 1st, 2006             125711   \n",
       "3  31435620458         Sports  May 11th, 2007              45303   \n",
       "4   7684220326         Sports  Mar 17th, 2009              37131   \n",
       "\n",
       "  Daily Average Views Min Daily Earning Max Daily Earning Min Monthly Earning  \\\n",
       "0            13416000              3400             53700              100600   \n",
       "1            15396600              3800             61600              115500   \n",
       "2            88514800             22100            354100              663900   \n",
       "3            24296400              6100             97200              182200   \n",
       "4             7820910              2000             31300               58700   \n",
       "\n",
       "  Max Monthly Earning Min Yearly Earning Max Yearly Earning  \\\n",
       "0             1.6e+06            1.2e+06           1.93e+07   \n",
       "1             1.8e+06            1.4e+06           2.22e+07   \n",
       "2            1.06e+07              8e+06          1.275e+08   \n",
       "3             2.9e+06            2.2e+06            3.5e+07   \n",
       "4              938500             703900           1.13e+07   \n",
       "\n",
       "  World Subscriber Rank World Video View Rank  \\\n",
       "0                     3                    11   \n",
       "1                     7                    36   \n",
       "2                    11                     7   \n",
       "3                    12                     3   \n",
       "4                    13                   111   \n",
       "\n",
       "                                                 URL  \n",
       "0     https://socialblade.com/youtube/user/pewdiepie  \n",
       "1  https://socialblade.com/youtube/user/295-dw_td...  \n",
       "2     https://socialblade.com/youtube/user/checkgate  \n",
       "3  https://socialblade.com/youtube/user/wwefannation  \n",
       "4    https://socialblade.com/youtube/user/corycotton  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels = pd.DataFrame(channels)\n",
    "channels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels.to_csv('top250_us_youtube_by_subs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
